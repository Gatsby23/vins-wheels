%YAML:1.0

#common parameters  
# rosrun vins vins_node  src/VINS/VINS-Fusion/config/three_cam/mynteye_stereo_config.yaml
#support: 1 imu 1 cam; 1 imu 2 cam: 2 cam; 
imu: 1
num_of_cam: 2  

imu_topic: "/imu0"
image0_topic: "/cam0/image_raw"
image1_topic: "/cam0/image_raw"
output_path: "/home/zhangs/vins_fusion/"

cam0_calib: "left_pinhole.yaml"
cam1_calib: "right_pinhole.yaml"
# cam0_calib: "left_equ.yaml"
# cam1_calib: "right_equ.yaml"
# cam0_calib: "left_mei.yaml"
# cam1_calib: "right_mei.yaml"
image_width: 640 
image_height: 480
   

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.

body_T_cam0: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [-0.9995250378696743, 0.0075019185074052044, -0.02989013031643309, 0.045574835649698026,
          0.029615343885863205, -0.03439736061393144, -0.998969345370175, -0.071161801837997044,
          -0.008522328211654736, -0.9993800792498829, 0.03415885127385616, -0.044681254117144367,
          0.0, 0.0, 0.0, 1.0]

body_T_cam1: !!opencv-matrix
   rows: 4
   cols: 4
   dt: d
   data: [ 0.999999445773493,   0.000791687752817,   0.000694034010224,   0.055488592,
           -0.000823363992158,   0.998899461915674,   0.046895490788700,   0.069215597,
           -0.000656143613644,  -0.046896036240590,   0.998899560146304,   0.043665904]

#body_T_cam0: !!opencv-matrix
#   rows: 4
#   cols: 4
#   dt: d
#   data: [ -9.9997682265467325e-01, 6.5076367365944354e-03, 2.0012040300038079e-03, 3.0710470880745057e-02,
#       -6.5115707349528967e-03, -9.9997686761696203e-01,   -1.9656239551802640e-03, -1.1619184937249040e-02,
#       1.9883661707245873e-03, -1.9786093788315136e-03,  9.9999606574470934e-01, 1.3708056410108752e-02, 
#                   0., 0., 0., 1. ]
#body_T_cam1: !!opencv-matrix
#   rows: 4
#   cols: 4
#   dt: d
#   data: [ -9.9996481469059639e-01, 7.5082204823142557e-03,
#       3.7411236265824004e-03, -4.8372430610697889e-02,
#       -7.5294931542847846e-03, -9.9995537938366685e-01,
#       -5.7049079314248205e-03, -1.2162086098338444e-02,
#       3.6981229887599635e-03, -5.7328759672098219e-03,
#       9.9997672873897647e-01, 1.0449454342939922e-02, 0., 0., 0., 1. ]

#body_T_cam0: !!opencv-matrix
#   rows: 4
#   cols: 4
#   dt: d
#   data: [-0.99994104,  0.00869258, -0.0065076,   0.04198236,
#          -0.00873295, -0.99994264,  0.00620169, -0.001833,
#           -0.00645332,  0.00625816,  0.99995959,  0.00924858,
#           0, 0, 0, 1]
#
#body_T_cam1: !!opencv-matrix
#   rows: 4
#   cols: 4
#   dt: d
#   data: [ -0.9999461,   0.01014244,  0.00221915, -0.0378247,
#           -0.01010622, -0.99982465,  0.01576488, -0.00238451,
#           0.00237866,  0.0157416,   0.99987326,  0.00893952,
#          0., 0., 0., 1. ]

#Multiple thread support
multiple_thread: 1

#feature traker paprameters
max_cnt: 150            # max feature number in feature tracking
min_dist: 30            # min distance between two features 
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)
